# ğŸš€ TPs Big Data avec Spark, Cassandra & Docker

## ğŸ‘¨â€ğŸ’» Auteur: **Mohamed YOULA** 

## ğŸ¯ Objectif 
Ces travaux pratiques visent Ã  travailler sur les trois axes suivants: 
1. Manipulation de fichiers et **DataFrames** avec **Spark**   
2. IntÃ©gration de **Spark** avec **Cassandra** via **Docker**  
3. Classification non supervisÃ©e avec **K-Means** (MLlib)

---

## ğŸ“Œ Contenu

### 1ï¸âƒ£ TP Spark â€” Lecture & Ã‰criture de DataFrames
- Lecture de fichiers **CSV**, **TXT**, **LIBSVM**
- CrÃ©ation de **DataFrames** depuis des **RDD**
- InfÃ©rence et dÃ©finition de **schÃ©mas**
- Calcul de **statistiques descriptives**
- Ã‰criture de DataFrames en **CSV**

---

### 2ï¸âƒ£ TP Spark + Cassandra (Docker)
- DÃ©ploiement dâ€™un conteneur **Cassandra** avec Docker
- CrÃ©ation dâ€™une base et de tables (**Restaurant**, **Inspection**)
- Import de donnÃ©es rÃ©elles (restaurants NYC)
- Lecture depuis Spark avec le **Cassandra Connector**
- Traitements distribuÃ©s : sÃ©lection, filtres, jointures, agrÃ©gations

---

### 3ï¸âƒ£ TP Classification K-Means
- GÃ©nÃ©ration de donnÃ©es 2D synthÃ©tiques
- Assemblage des variables en vecteurs de features
- Application de **K-Means** (k=5)
- Attribution des clusters aux points
- Ã‰valuation par le **coefficient de silhouette**
- Affichage des **centres des clusters**

---

## ğŸ› ï¸ PrÃ©requis
- **Apache Spark 3.x**
- **Python (PySpark)** & **Scala**
- **Docker Desktop**
- **Cassandra** + **Spark Cassandra Connector**

---

## âœ… Connaissances acquises
- Savoir lire/Ã©crire diffÃ©rents formats de donnÃ©es avec Spark  
- Connecter Spark Ã  Cassandra et manipuler des donnÃ©es distribuÃ©es  
- Appliquer un algorithme de **clustering** (K-Means) et Ã©valuer ses performances  

---
